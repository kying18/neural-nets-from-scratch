"""
Animation and visualization tools for the neural network library.

This file was generated by Cursor.
"""

import traceback
import warnings

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.animation import FFMpegWriter, FuncAnimation, PillowWriter
from matplotlib.cm import ScalarMappable
from matplotlib.colors import LinearSegmentedColormap, Normalize
from matplotlib.lines import Line2D
from matplotlib.patches import Rectangle

from scipy.interpolate import RBFInterpolator, griddata

warnings.filterwarnings('ignore')


# Playground.tensorflow.org color scheme
PLAYGROUND_COLORS = {
    'class_0': '#D87373',
    'class_1': '#3E6589',
    'background': '#FFFFFF',
    'grid': '#D3D3D3',
    'text': '#2C3E50',
    'accent': '#FFD93D',
}


def create_visualization_colormap():
    # red to white to blue
    colors = ['#D87373', '#FFFFFF', '#3E6589']
    n_bins = 256
    cmap = LinearSegmentedColormap.from_list('visualization', colors, N=n_bins)
    return cmap


def animate_decision_boundary_training(model, X, y, recorder, resolution=200, 
                                      fps=10, save_path="decision_boundary_training.mp4"):
    """
    Create animated video of decision boundary evolving during training.
    
    Args:
        model: Sequential model
        X: Training data (N, 2) - uses first 2 dimensions
        y: Labels (N,)
        recorder: TrainingRecorder with training history
        resolution: Grid resolution
        fps: Frames per second
        title: Video title
        save_path: Path to save video
    """
    # Create mesh
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),
                        np.linspace(y_min, y_max, resolution))
    
    mesh_points = np.c_[xx.ravel(), yy.ravel()]
    
    # Check if model expects 3D input
    if hasattr(model.layers[0], 'W') and model.layers[0].W.shape[0] == 3:
        r = np.sqrt(mesh_points[:, 0]**2 + mesh_points[:, 1]**2).reshape(-1, 1)
        mesh_input = np.hstack([mesh_points, r])
    else:
        mesh_input = mesh_points
    
    # Setup figure (16:9)
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)
    
    # Create colormap
    cmap = create_visualization_colormap()
    
    # Initial plot
    recorder.restore_model_state(model, recorder.get_all_epochs()[0])
    Z = model.forward(mesh_input)
    if Z.shape[1] == 1:
        Z = Z.reshape(xx.shape)
    else:
        Z = Z[:, 0].reshape(xx.shape)
    
    contour = ax.contourf(xx, yy, Z, levels=100, cmap=cmap, alpha=1.0, vmin=0, vmax=1)
    ax.contour(xx, yy, Z, levels=[0.5], colors='#1F2D3D', linewidths=2.0, linestyles='--', alpha=0.9)
    
    # Plot data points with playground colors
    scatter = ax.scatter(
        X[:, 0],
        X[:, 1],
        c=[PLAYGROUND_COLORS['class_0'] if label == 0 else PLAYGROUND_COLORS['class_1']
           for label in y.flatten()],
        edgecolors='white',
        linewidths=2,
        s=80,
        alpha=0.95,
        zorder=10
    )
    
    # Colorbar (vertical, anchored inside the right side)
    pos = ax.get_position()
    cbar_width = 0.01 * pos.width
    cbar_height = 0.6 * pos.height
    cbar_left = pos.x1 - cbar_width * 5
    cbar_bottom = pos.y0 + (pos.height - cbar_height) / 2
    cbar_ax = fig.add_axes([cbar_left, cbar_bottom, cbar_width, cbar_height])
    # Use ScalarMappable with explicit 0-1 normalization
    sm = ScalarMappable(norm=Normalize(vmin=0, vmax=1), cmap=cmap)
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=cbar_ax, orientation='vertical', ticks=[0.0, 0.25, 0.5, 0.75, 1.0])
    cbar.ax.tick_params(colors=PLAYGROUND_COLORS['text'], labelsize=16, length=0)
    cbar.outline.set_edgecolor('none')
    cbar.ax.set_ylabel('Prediction Confidence', fontsize=16, fontweight='bold',
                       color=PLAYGROUND_COLORS['text'], labelpad=10)
    
    def _style_axes(axis: plt.Axes):
        axis.set_facecolor('white')
        axis.set_xlim(x_min, x_max)
        axis.set_ylim(y_min, y_max)
        # Move x-axis tick labels to top (inside plot when ticks are at bottom)
        # Move y-axis tick labels to right (inside plot when ticks are at left)
        axis.tick_params(axis='x', which='major', labeltop=False, labelbottom=True, pad=-25, labelsize=16)
        axis.tick_params(axis='y', which='major', labelright=False, labelleft=True, pad=-35, labelsize=16)
        for spine in axis.spines.values():
            spine.set_visible(False)
        axis.grid(True, color=PLAYGROUND_COLORS['grid'], alpha=0.25, linestyle='--', linewidth=0.6)
    
    _style_axes(ax)
    
    # Info text (figure-level so it persists when axis clears)
    info_text = fig.text(
        0.06,
        0.93,
        '',
        fontsize=16,
        fontweight='bold',
        color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )
    
    # Animation function
    def animate(frame):
        ax.clear()
        
        epoch = recorder.get_all_epochs()[frame]
        state = recorder.get_state_at_epoch(epoch)
        
        # Restore model state
        recorder.restore_model_state(model, epoch)
        
        # Recompute decision boundary
        Z = model.forward(mesh_input)
        if Z.shape[1] == 1:
            Z = Z.reshape(xx.shape)
        else:
            Z = Z[:, 0].reshape(xx.shape)
        
        # Plot
        contour = ax.contourf(xx, yy, Z, levels=100, cmap=cmap, alpha=1.0, vmin=0, vmax=1)
        ax.contour(xx, yy, Z, levels=[0.5], colors='#1F2D3D', linewidths=2.0, linestyles='--', alpha=0.9)
        
        scatter = ax.scatter(
            X[:, 0],
            X[:, 1],
            c=[PLAYGROUND_COLORS['class_0'] if label == 0 else PLAYGROUND_COLORS['class_1']
               for label in y.flatten()],
            edgecolors='white',
            linewidths=2,
            s=80,
            alpha=0.95,
            zorder=10
        )
        
        _style_axes(ax)
        
        # Update info text
        loss_val = state.get('loss', 0)
        acc_val = state.get('accuracy', 0)
        info_text.set_text(f"Epoch {epoch}\nLoss: {loss_val:.4f} | Acc: {acc_val:.2%}")
        
        return contour, scatter, info_text
    
    # Create animation
    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps, 
                        blit=False, repeat=True)
    
    # Save video
    print(f"Creating video with {n_frames} frames...")
    try:
        # Try FFmpeg first (better quality)
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")
    
    return anim, fig


def animate_dataset_scatter_plot(X, y, batch_size, fps=10, save_path="dataset_scatter.mp4"):
    """
    Create animated video of dataset scatter plot.
    Starts with just axes, then plots each point one by one, initially without color.
    
    Args:
        X: Training data (N, 2) - uses first 2 dimensions
        y: Labels (N,)
        fps: Frames per second
        save_path: Path to save the video (MP4)
    """
    n_samples = len(X)
    
    # Calculate axis limits (same as decision boundary)
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    
    # Setup figure (16:9) - same as decision boundary
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)
    
    def _style_axes(axis: plt.Axes):
        axis.set_facecolor('white')
        axis.set_xlim(x_min, x_max)
        axis.set_ylim(y_min, y_max)
        axis.tick_params(axis='x', which='both', length=0)  # Remove tick marks X
        axis.tick_params(axis='y', which='both', length=0)  # Remove tick marks Y
        # Same tick styling as decision boundary (keep labels)
        axis.tick_params(axis='x', which='major', labeltop=False, labelbottom=True, pad=-25, labelsize=16)
        axis.tick_params(axis='y', which='major', labelright=False, labelleft=True, pad=-45, labelsize=16)
        for spine in axis.spines.values():
            spine.set_visible(False)
        axis.grid(True, color=PLAYGROUND_COLORS['grid'], alpha=0.25, linestyle='--', linewidth=0.6)
    
    # Style axes initially (no points yet)
    _style_axes(ax)
    
    # Info text
    info_text = fig.text(
        0.06,
        0.93,
        '',
        fontsize=16,
        fontweight='bold',
        color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )
    
    # Calculate batches
    n_batches = (n_samples + batch_size - 1) // batch_size  # Ceiling division
    
    # Animation function
    def animate(frame):
        ax.clear()
        _style_axes(ax)
        
        # Frame 0: Just axes
        if frame == 0:
            info_text.set_text(f"Dataset: {n_samples} points")
        # Frames 1 to n_batches: Plot points in batches of 10 (gray)
        elif frame <= n_batches:
            batch_idx = frame
            points_to_show = min(batch_idx * batch_size, n_samples)
            x_vals = X[:points_to_show, 0]
            y_vals = X[:points_to_show, 1]
            
            # Use gray for all points initially (no color)
            colors = ['#808080'] * points_to_show  # Gray color
            
            scatter = ax.scatter(
                x_vals,
                y_vals,
                c=colors,
                edgecolors='white',
                linewidths=2,
                s=80,
                alpha=0.95,
                zorder=10
            )
            
            info_text.set_text(f"Dataset: {points_to_show}/{n_samples} points")
        # Frame n_batches + 1: All points shown in gray
        elif frame == n_batches + 1:
            # All points in gray
            scatter = ax.scatter(
                X[:, 0],
                X[:, 1],
                c=['#808080'] * n_samples,
                edgecolors='white',
                linewidths=2,
                s=80,
                alpha=0.95,
                zorder=10
            )
            info_text.set_text(f"Dataset: {n_samples} points")
        # Frame n_batches + 2: Add class 0 color
        elif frame == n_batches + 2:
            # Color class 0 points, keep class 1 gray
            colors = [PLAYGROUND_COLORS['class_0'] if label == 0 else '#808080'
                     for label in y.flatten()]
            
            scatter = ax.scatter(
                X[:, 0],
                X[:, 1],
                c=colors,
                edgecolors='white',
                linewidths=2,
                s=80,
                alpha=0.95,
                zorder=10
            )
            
            # Add class 0 label
            ax.text(0.95, 0.95, 'Class 0', transform=ax.transAxes,
                   fontsize=18, fontweight='bold', color=PLAYGROUND_COLORS['class_0'],
                   ha='right', va='top',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9,
                            edgecolor=PLAYGROUND_COLORS['class_0'], linewidth=2))
            
            info_text.set_text(f"Dataset: {n_samples} points")
        # Frame n_batches + 3: Add class 1 color
        else:
            # All points with their class colors
            colors = [PLAYGROUND_COLORS['class_0'] if label == 0 else PLAYGROUND_COLORS['class_1']
                     for label in y.flatten()]
            
            scatter = ax.scatter(
                X[:, 0],
                X[:, 1],
                c=colors,
                edgecolors='white',
                linewidths=2,
                s=80,
                alpha=0.95,
                zorder=10
            )
            
            # Add both class labels
            ax.text(0.95, 0.95, 'Class 0', transform=ax.transAxes,
                   fontsize=18, fontweight='bold', color=PLAYGROUND_COLORS['class_0'],
                   ha='right', va='top',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9,
                            edgecolor=PLAYGROUND_COLORS['class_0'], linewidth=2))
            ax.text(0.95, 0.88, 'Class 1', transform=ax.transAxes,
                   fontsize=18, fontweight='bold', color=PLAYGROUND_COLORS['class_1'],
                   ha='right', va='top',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9,
                            edgecolor=PLAYGROUND_COLORS['class_1'], linewidth=2))
            
            info_text.set_text(f"Dataset: {n_samples} points")
        
        return ax, info_text
    
    # Create animation: 
    # - Frame 0: axes only
    # - Frames 1 to n_batches: add points in batches of 10 (gray)
    # - Frame n_batches + 1: all points gray
    # - Frame n_batches + 2: add class 0 color + label
    # - Frame n_batches + 3+: add class 1 color + both labels (hold for a few frames)
    n_frames = 1 + n_batches + 1 + 1 + 5  # 1 (axes) + batches + 1 (all gray) + 1 (class 0) + 5 (class 1 hold)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                        blit=False, repeat=True)
    
    # Save video
    print(f"Creating dataset scatter plot video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")
    
    return anim, fig


def animate_probability_distribution(model, X, y, recorder, fps=10,
                                     save_path="probability_distribution.mp4"):
    """
    Create animated video showing how predicted probabilities evolve during training.
    Points are displayed on a number line from 0 to 1, colored by true label.
    
    Args:
        model: Sequential model
        X: Training data (N, features)
        y: Labels (N,)
        recorder: TrainingRecorder with training history
        fps: Frames per second
        save_path: Path to save video
    """
    n_samples = len(X)
    x_min, x_max = -0, 1
    y_min, y_max = -0.5, n_samples * 0.02 + 0.5
    
    # Setup figure (16:9)
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0, right=1, top=1, bottom=0.07)
    
    # Create y-offset based on index to spread points vertically
    y_offset = np.arange(n_samples) * 0.02  # Small vertical offset per point
    
    # Get initial predictions
    recorder.restore_model_state(model, recorder.get_all_epochs()[0])
    initial_probs = model.forward(X)
    if initial_probs.shape[1] == 1:
        initial_probs = initial_probs.flatten()
    else:
        initial_probs = initial_probs[:, 0]
    
    def _style_probability_axes(axis: plt.Axes):
        # axis.set_facecolor('white')
        axis.set_xlim(x_min, x_max)
        axis.set_ylim(y_min, y_max)
        # Show x-axis ticks, hide y-axis ticks
        axis.tick_params(axis='x', which='both', length=0, colors=PLAYGROUND_COLORS['text'], labelsize=16)  # Hide x-axis tick marks
        axis.tick_params(axis='y', which='both', length=0)  # Hide y-axis tick marks
        axis.set_xticks([0.05, 0.95])
        axis.set_xticklabels(['Class 0', 'Class 1']) 
        axis.set_xlabel('Prediction', fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'])
        for spine in axis.spines.values():
            spine.set_visible(False)
        axis.grid(True, color=PLAYGROUND_COLORS['grid'], alpha=0.25, linestyle='--', linewidth=0.6)
    
    def _draw_scatter(axis: plt.Axes, probs):
        scatter_plot = axis.scatter(
            probs,
            y_offset,
            c=[PLAYGROUND_COLORS['class_0'] if label == 0 else PLAYGROUND_COLORS['class_1']
               for label in y.flatten()],
            edgecolors='white',
            linewidths=1.5,
            s=55,
            alpha=0.85,
            zorder=10
        )
        axis.axvline(x=0.5, color='#1F2D3D', linestyle='--', linewidth=2, alpha=0.6)
        return scatter_plot
    
    _style_probability_axes(ax)
    scatter = _draw_scatter(ax, initial_probs)
    
    # Info text (figure-level so it persists when axis clears)
    info_text = fig.text(
        0.06,
        0.93,
        '',
        fontsize=16,
        fontweight='bold',
        color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )
    
    # Animation function
    def animate(frame):
        ax.clear()
        
        epoch = recorder.get_all_epochs()[frame]
        state = recorder.get_state_at_epoch(epoch)
        
        # Restore model state
        recorder.restore_model_state(model, epoch)
        
        # Get predictions
        probs = model.forward(X)
        if probs.shape[1] == 1:
            probs = probs.flatten()
        else:
            probs = probs[:, 0]
        
        # Plot points
        scatter = _draw_scatter(ax, probs)
        _style_probability_axes(ax)
        
        # Update info text
        loss_val = state.get('loss', 0)
        acc_val = state.get('accuracy', 0)
        info_text.set_text(f"Epoch {epoch}\nLoss: {loss_val:.4f} | Acc: {acc_val:.2%}")
        
        return scatter, info_text
    
    # Create animation
    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                        blit=False, repeat=True)
    
    # Save video
    print(f"Creating probability distribution video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")
    
    return anim, fig


def animate_training_loss(recorder, fps=10, save_path="training_loss.mp4"):
    """
    Create animated video showing training and test loss over epochs.
    Lines grow as training progresses with fixed axis ranges.
    """
    epochs = [state['epoch'] for state in recorder.history]
    train_losses = [state['loss'] for state in recorder.history]
    test_losses = [state.get('test_loss', 0) for state in recorder.history]

    max_loss = max(max(train_losses), max(test_losses)) * 1.1
    min_loss = 0

    # Use green for train, purple for test
    train_color = '#2ECC71'  # Green
    test_color = '#9B59B6'    # Purple

    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0.05, right=0.95, top=0.93, bottom=0.07)

    def _style_axis(axis: plt.Axes, x_lim, y_lim):
        axis.set_facecolor('white')
        axis.set_xlim(x_lim)
        axis.set_ylim(y_lim)
        axis.set_xlabel('Epoch', fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'])
        axis.set_ylabel('Loss', fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'])
        axis.tick_params(colors=PLAYGROUND_COLORS['text'], labelsize=15, length=0)
        for spine in axis.spines.values():
            spine.set_visible(False)
        axis.grid(True, color=PLAYGROUND_COLORS['grid'], alpha=0.25, linestyle='--', linewidth=0.6)

    info_text = fig.text(
        0.06, 0.93, '',
        fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )

    def animate(frame):
        ax.clear()

        current_epochs = epochs[:frame+1]
        current_train_losses = train_losses[:frame+1]
        current_test_losses = test_losses[:frame+1]

        ax.plot(current_epochs, current_train_losses, color=train_color,
                 linewidth=4.0, alpha=0.9, label='Train')
        ax.plot(current_epochs, current_test_losses, color=test_color,
                 linewidth=4.0, alpha=0.9, label='Test')
        _style_axis(ax, (0, max(epochs)), (min_loss, max_loss))
        legend = ax.legend(loc='lower left', frameon=False, fontsize=16)
        for text in legend.get_texts():
            text.set_color(PLAYGROUND_COLORS['text'])

        info_text.set_text(
            f"Epoch {current_epochs[-1]}"
            f"\nLoss: {current_train_losses[-1]:.4f} / {current_test_losses[-1]:.4f}"
        )

        return ax, info_text

    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                         blit=False, repeat=True)

    print(f"Creating training loss video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")

    return anim, fig


def animate_training_accuracy(recorder, fps=10, save_path="training_accuracy.mp4"):
    """
    Create animated video showing training and test accuracy over epochs.
    Lines grow as training progresses with fixed axis ranges.
    """
    epochs = [state['epoch'] for state in recorder.history]
    train_accuracies = [state.get('accuracy', 0) for state in recorder.history]
    test_accuracies = [state.get('test_accuracy', 0) for state in recorder.history]

    min_acc = min(min(train_accuracies), min(test_accuracies)) * 0.9 if min(train_accuracies) > 0 else 0
    max_acc = 1.0

    # Use green for train, purple for test
    train_color = '#2ECC71'  # Green
    test_color = '#9B59B6'    # Purple

    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0.05, right=0.95, top=0.93, bottom=0.07)

    def _style_axis(axis: plt.Axes, x_lim, y_lim):
        axis.set_facecolor('white')
        axis.set_xlim(x_lim)
        axis.set_ylim(y_lim)
        axis.set_xlabel('Epoch', fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'])
        axis.set_ylabel('Accuracy', fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'])
        axis.tick_params(colors=PLAYGROUND_COLORS['text'], labelsize=16, length=0)
        for spine in axis.spines.values():
            spine.set_visible(False)
        axis.grid(True, color=PLAYGROUND_COLORS['grid'], alpha=0.25, linestyle='--', linewidth=0.6)

    info_text = fig.text(
        0.06, 0.93, '',
        fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )

    def animate(frame):
        ax.clear()

        current_epochs = epochs[:frame+1]
        current_train_accs = train_accuracies[:frame+1]
        current_test_accs = test_accuracies[:frame+1]

        ax.plot(current_epochs, current_train_accs, color=train_color,
                 linewidth=4.0, alpha=0.9, label='Train')
        ax.plot(current_epochs, current_test_accs, color=test_color,
                 linewidth=4.0, alpha=0.9, label='Test')
        _style_axis(ax, (0, max(epochs)), (min_acc, max_acc))
        legend = ax.legend(loc='lower right', frameon=False, fontsize=16)
        for text in legend.get_texts():
            text.set_color(PLAYGROUND_COLORS['text'])

        info_text.set_text(
            f"Epoch {current_epochs[-1]}"
            f"\nAcc: {current_train_accs[-1]:.2%} / {current_test_accs[-1]:.2%}"
        )

        return ax, info_text

    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                         blit=False, repeat=True)

    print(f"Creating training accuracy video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")

    return anim, fig


def animate_network_architecture(model, X, recorder, fps=10, save_path="network_architecture.mp4",
                                  layer_spacing=6.0, padding=0.3):
    """
    Create animated video showing neural network architecture with neuron activation visualization.
    Each neuron node shows its activation pattern as a visualization.
    
    Args:
        model: Sequential model
        X: Input data (N, features) - used to compute activations
        recorder: TrainingRecorder with training history
        fps: Frames per second
        save_path: Path to save video
        layer_spacing: Horizontal spacing between layers
        padding: Padding between neurons in a column (as fraction of node size)
    """
    # Extract layer information (only Linear layers)
    linear_layers = []
    layer_dims = []
    activation_layers = []  # All layers (including activations)
    
    for layer in model.layers:
        if hasattr(layer, 'W'):
            linear_layers.append(layer)
            in_dim = layer.W.shape[0]
            out_dim = layer.W.shape[1]
            layer_dims.append((in_dim, out_dim))
        activation_layers.append(layer)
    
    if len(linear_layers) == 0:
        raise ValueError("No Linear layers found in model")
    
    # Determine input dimension (first layer's input)
    input_dim = layer_dims[0][0]
    layer_dims.insert(0, (input_dim, None))  # Add input layer
    
    # Calculate max neurons in any layer to determine node size
    neuron_counts = [layer_dims[0][0]]  # input layer
    neuron_counts.extend([dims[1] for dims in layer_dims[1:] if dims[1] is not None])  # output layers
    max_neurons = max(neuron_counts) if neuron_counts else 1
    
    # Calculate available vertical space
    # Estimate based on number of layers and neurons
    # Use a reasonable scale: if max_neurons is large, make nodes smaller
    # Target: nodes should be visible but not overlap
    # Make neurons larger (increased base sizes)
    if max_neurons <= 5:
        base_size = 2.0
    elif max_neurons <= 10:
        base_size = 1.6
    elif max_neurons <= 20:
        base_size = 1.0
    else:
        base_size = 0.6
    
    # Calculate node size with padding
    # Use rectangular shape: width and height
    node_width = base_size * 1.2  # Slightly wider for rectangular shape
    node_height = base_size
    neuron_radius = max(node_width, node_height) / 2  # For spacing calculations
    
    # Calculate neuron spacing based on node size and padding
    neuron_spacing = node_height * (1 + padding)
    
    # Calculate positions for neurons
    neuron_positions = {}  # {(layer_idx, neuron_idx): (x, y)}
    
    # Layout neurons
    # Layer 0 is input, then each subsequent layer is the output of a Linear layer
    for layer_idx in range(len(layer_dims)):
        if layer_idx == 0:
            # Input layer
            in_dim, _ = layer_dims[0]
            n_neurons = in_dim
            x_pos = 0
        else:
            # Output layer of the (layer_idx-1)th Linear layer
            _, out_dim = layer_dims[layer_idx]
            n_neurons = out_dim
            x_pos = layer_idx * layer_spacing
        
        # Center neurons vertically
        total_height = (n_neurons - 1) * neuron_spacing
        start_y = -total_height / 2
        
        for neuron_idx in range(n_neurons):
            y_pos = start_y + neuron_idx * neuron_spacing
            neuron_positions[(layer_idx, neuron_idx)] = (x_pos, y_pos)
    
    # Helper function to compute activations at each layer
    def compute_layer_activations(model, X):
        """Compute activations at each layer for given input."""
        activations = {}
        current_input = X
        
        # Input layer activations (just the input)
        activations[0] = current_input
        
        layer_idx = 1
        for layer in model.layers:
            current_input = layer.forward(current_input)
            # Store activations after each layer (including activations)
            activations[layer_idx] = current_input
            layer_idx += 1
        
        return activations
    
    # Compute activations for a sample of inputs (use mean for visualization)
    # Use a subset of data for performance
    sample_size = min(100, len(X))
    X_sample = X[:sample_size]
    
    # Get activation range across all epochs for consistent scaling
    all_activations = []
    for epoch in recorder.get_all_epochs():
        recorder.restore_model_state(model, epoch)
        activations = compute_layer_activations(model, X_sample)
        for layer_idx, act in activations.items():
            all_activations.append(act.flatten())
    
    all_act_values = np.concatenate(all_activations)
    max_activation = np.abs(all_act_values).max() if len(all_act_values) > 0 else 1.0
    
    # Setup figure (16:9) - use full width, no padding
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0.0, right=1.0, top=1.0, bottom=0.0)
    ax.set_facecolor('white')
    ax.set_aspect('equal')
    ax.axis('off')
    
    # Create colormap for activations
    activation_cmap = create_visualization_colormap()
    
    def _style_network_axis(axis: plt.Axes):
        axis.set_facecolor('white')
        axis.set_aspect('equal')
        axis.axis('off')
    
    _style_network_axis(ax)
    
    # Info text (figure level)
    info_text = fig.text(
        0.06,
        0.93,
        '',
        fontsize=16,
        fontweight='bold',
        color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )
    
    # Animation function
    def animate(frame):
        try:
            ax.clear()
            _style_network_axis(ax)
            
            epochs = recorder.get_all_epochs()
            if frame >= len(epochs):
                return []
            
            epoch = epochs[frame]
            state = recorder.get_state_at_epoch(epoch)
            
            # Restore model state
            recorder.restore_model_state(model, epoch)
            
            # Compute current activations
            activations = compute_layer_activations(model, X_sample)
            
            # Draw network with activations
            _draw_network_with_activations(ax, model, layer_dims, neuron_positions, neuron_radius,
                                          activations, activation_cmap, max_activation, X_sample, layer_spacing,
                                          node_width, node_height)
            
            # Update info text
            loss_val = state.get('loss', 0)
            acc_val = state.get('accuracy', 0)
            info_text.set_text(f"Epoch {epoch}\nLoss: {loss_val:.4f} | Acc: {acc_val:.2%}")
            
            return [info_text]
        except Exception as e:
            print(f"Error in animation frame {frame}: {e}")
            traceback.print_exc()
            return []
    
    # Create animation
    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                        blit=False, repeat=True)
    
    # Save video
    print(f"Creating network architecture video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")
    
    return anim, fig


def _draw_network_with_activations(ax, model, layer_dims, neuron_positions, neuron_radius,
                                   activations_dict, activation_cmap, max_activation, X_sample, layer_spacing,
                                   node_width=None, node_height=None):
    """Helper function to draw the network architecture with activation visualizations."""
    
    # Use provided dimensions or default to square
    if node_width is None:
        node_width = neuron_radius * 2
    if node_height is None:
        node_height = neuron_radius * 2
    
    # Set axis limits based on neuron positions - include space for labels
    if neuron_positions:
        all_x = [pos[0] for pos in neuron_positions.values()]
        all_y = [pos[1] for pos in neuron_positions.values()]
        x_min, x_max = min(all_x), max(all_x)
        y_min, y_max = min(all_y), max(all_y)
        ax.set_xlim(x_min - node_width/2, x_max + node_width/2)
        # Add padding: top for labels, bottom for spacing below last neuron
        ax.set_ylim(y_min - node_height/2 - 1.0, y_max + node_height/2 + 1.0)
    
    # Extract linear layers for drawing connections
    linear_layers = []
    for layer in model.layers:
        if hasattr(layer, 'W'):
            linear_layers.append(layer)
    
    # Get max weight for connection visualization
    all_weights = []
    for layer in linear_layers:
        all_weights.append(np.abs(layer.W).max())
    max_weight = max(all_weights) if all_weights else 1.0
    
    # Draw connections (weights)
    layer_idx = 1  # Start from first hidden layer (skip input layer)
    for layer in linear_layers:
        W = layer.W  # Shape: (in_dim, out_dim)
        in_dim, out_dim = W.shape
        
        # Draw connections from previous layer to current layer
        for i in range(in_dim):
            for j in range(out_dim):
                weight = W[i, j]
                weight_abs = abs(weight)
                
                # Get positions
                if layer_idx == 1:
                    start_pos = neuron_positions[(0, i)]
                else:
                    start_pos = neuron_positions[(layer_idx - 1, i)]
                
                end_pos = neuron_positions[(layer_idx, j)]
                
                # Line width proportional to weight magnitude
                line_width = max(0.05, (weight_abs / max_weight) * 3.0) if max_weight > 0 else 0.05
                
                # Color based on weight sign (blue for negative, red for positive, gray for zero)
                if weight > 0:
                    color = '#D62728'  # Red for positive weights
                elif weight < 0:
                    color = '#1F77B4'  # Blue for negative weights
                else:
                    color = '#95A5A6'  # Neutral gray for zero weights

                # Draw connection
                ax.plot([start_pos[0], end_pos[0]], [start_pos[1], end_pos[1]],
                       color=color, linewidth=line_width, alpha=0.5, zorder=1)
        
        layer_idx += 1

    # Helper function to compute activations (needed for mesh)
    def compute_layer_activations_local(model, X):
        """Compute activations at each layer for given input."""
        activations = {}
        current_input = X
        activations[0] = current_input
        layer_idx = 1
        for layer in model.layers:
            current_input = layer.forward(current_input)
            activations[layer_idx] = current_input
            layer_idx += 1
        return activations
    
    # Build mapping from layer_dims index to activations_dict index
    # layer_dims[0] = input = activations_dict[0]
    # layer_dims[1] = first hidden output (after first Linear+Activation)
    # layer_dims[2] = second hidden output (after second Linear+Activation)
    layer_to_activation_map = {0: 0}  # Input layer maps to activations[0]
    linear_count = 0
    for i, layer in enumerate(model.layers):
        if hasattr(layer, 'W'):
            linear_count += 1
            # Check if next layer is activation
            if i + 1 < len(model.layers) and not hasattr(model.layers[i + 1], 'W'):
                # After processing Linear+Activation, we have an output layer
                # activations_dict stores after each layer, so after Linear is i+1, after Activation is i+2
                layer_to_activation_map[linear_count] = i + 2
    
    # Helper function to get activation for a specific neuron
    def get_neuron_activation(activations_dict, target_layer_idx, target_neuron_idx):
        """Get activation for a specific neuron from activations dictionary."""
        try:
            if target_layer_idx not in layer_to_activation_map:
                return None
            
            activation_idx = layer_to_activation_map[target_layer_idx]
            if activation_idx not in activations_dict:
                return None
            
            act = activations_dict[activation_idx]
            if act is None or len(act.shape) < 2:
                return None
            
            if act.shape[1] > target_neuron_idx:
                return act[:, target_neuron_idx]
            return None
        except (IndexError, KeyError, AttributeError) as e:
            return None
    
    # Create meshgrid for activation visualization (only for 2D input)
    # Compute mesh activations once for all neurons
    mesh_activations_all = None
    xx = yy = None
    if X_sample.shape[1] >= 2:
        res = 30  # Resolution for neuron visualization
        x_min, x_max = X_sample[:, 0].min() - 0.5, X_sample[:, 0].max() + 0.5
        y_min, y_max = X_sample[:, 1].min() - 0.5, X_sample[:, 1].max() + 0.5
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, res),
                            np.linspace(y_min, y_max, res))
        mesh_points = np.c_[xx.ravel(), yy.ravel()]
        
        # Check if model expects 3D input
        if hasattr(model.layers[0], 'W') and model.layers[0].W.shape[0] == 3:
            r = np.sqrt(mesh_points[:, 0]**2 + mesh_points[:, 1]**2).reshape(-1, 1)
            mesh_input = np.hstack([mesh_points, r])
        else:
            mesh_input = mesh_points
        
        # Compute activations for mesh once
        mesh_activations_all = compute_layer_activations_local(model, mesh_input)
    
    # Draw neurons with activation visualizations
    for (layer_idx, neuron_idx), (x, y) in neuron_positions.items():
        if layer_idx == 0:
            # Input neurons: just represent the raw input features (x1, x2)
            # Use simple solid colors to distinguish them
            # Assign a unique color for each input feature for up to 10 inputs, then cycle if more
            input_colors = [
                '#E8F4F8',  # Light blue
                '#F8E8F4',  # Light pink
                '#F8F4E8',  # Light yellow
                '#E8F8E8',  # Light green
                '#F8EDE8',  # Light orange
                '#E8EAF8',  # Light lavender
                '#F8E8E8',  # Light rose
                '#E8F8F4',  # Light teal
                '#EDF8E8',  # Light mint
                '#F2E8F8',  # Light purple
            ]
            color = input_colors[neuron_idx % len(input_colors)]
            
            rect = Rectangle((x - node_width/2, y - node_height/2), 
                            node_width, node_height,
                            color=color,
                            edgecolor='black', linewidth=1, zorder=10)
            ax.add_patch(rect)
            
            # Add label to show which feature this is
            # Label from top to bottom as 1, 2, 3... (reverse of neuron_idx order)
            # Get total number of input neurons
            n_input_neurons = layer_dims[0][0]
            # Reverse the index so top neuron is x1, bottom is xN
            visual_idx = n_input_neurons - 1 - neuron_idx
            label = f'x{visual_idx + 1}'
            ax.text(x, y, label, ha='center', va='center', 
                   fontsize=10, fontweight='bold', color='black', zorder=11)
            continue
        
        # For hidden/output layers, compute and visualize activation
        if mesh_activations_all is not None and layer_idx > 0:
            # Get activation for this neuron from the pre-computed activations
            neuron_activations = get_neuron_activation(mesh_activations_all, layer_idx, neuron_idx)
            
            if neuron_activations is not None:
                # Reshape to grid
                Z = neuron_activations.reshape(xx.shape)
                
                # Determine if this is the output layer (last layer)
                is_output_layer = (layer_idx == len(layer_dims) - 1)
                
                if is_output_layer:
                    # Output layer: use decision boundary colormap (probability: 0 to 1)
                    # Normalize to [0, 1] range for probability visualization
                    Z_norm = np.clip(Z, 0, 1)
                    
                    # Use decision boundary colormap
                    output_cmap = create_visualization_colormap()
                    Z_rgba = output_cmap(Z_norm)
                else:
                    # Hidden layers: use PuOr colormap
                    z_min, z_max = Z.min(), Z.max()
                    z_abs_max = max(abs(z_min), abs(z_max))
                    
                    if z_abs_max > 0:
                        if z_min < 0:
                            # Signed activations (Tanh, etc.): normalize to [-1, 1], then map to [0, 1]
                            Z_norm = Z / z_abs_max
                            # Map [-1, 1] to [0, 1] for color scheme
                            Z_colormap = (Z_norm + 1) / 2
                        else:
                            # Positive-only activations (ReLU): map 0 -> mid color(0.5), max -> max color (1.0)
                            # Map [0, max] to [0.5, 1.0] for color scheme
                            Z_colormap = 0.5 + (Z / z_max) * 0.5 if z_max > 0 else np.ones_like(Z) * 0.5
                    else:
                        Z_colormap = np.ones_like(Z) * 0.5  # White for zero activations
                    
                    Z_colormap = np.clip(Z_colormap, 0, 1)
                    
                    # Use PuOr colormap for hidden layers
                    Z_rgba = plt.cm.PuOr(Z_colormap)
                
                # Place the image at the neuron's position (rectangular)
                extent = (
                    x - node_width/2,
                    x + node_width/2,
                    y - node_height/2,
                    y + node_height/2
                )
                ax.imshow(Z_rgba, extent=extent, origin='lower', zorder=11, aspect='auto', interpolation='bilinear')
                
                # Overlay decision boundary (where activation = 0)
                # Transform grid coordinates to neuron-local coordinates
                try:
                    # Create coordinate grids in neuron-local space
                    x_local = np.linspace(x - node_width/2, x + node_width/2, res)
                    y_local = np.linspace(y - node_height/2, y + node_height/2, res)
                    xx_local, yy_local = np.meshgrid(x_local, y_local)
                    
                    ax.contour(
                        xx_local, yy_local, Z,
                        levels=[0],
                        colors='black',
                        linewidths=0.8,
                        zorder=12,
                        alpha=0.8
                    )
                except:
                    pass  # Skip if contour fails
        
        # Draw neuron outline (rectangular)
        rect = Rectangle((x - node_width/2, y - node_height/2), 
                        node_width, node_height,
                        color="none",
                        edgecolor='black', linewidth=1, zorder=14)
        ax.add_patch(rect)
    
    # Add layer labels (after setting axis limits to ensure they're visible)
    for layer_idx in range(len(layer_dims)):
        if layer_idx == 0:
            label = 'Input'
        elif layer_idx == len(layer_dims) - 1:
            label = 'Output'
        else:
            # Number hidden layers starting from 1
            hidden_num = layer_idx
            label = f'Hidden {hidden_num}'
        
        x_pos = 0 if layer_idx == 0 else layer_idx * layer_spacing
        
        layer_neurons = [pos for (l_idx, _), pos in neuron_positions.items() if l_idx == layer_idx]
        if layer_neurons:
            max_y = max([y for _, y in layer_neurons])
            # Position label above the top neuron with more spacing
            label_y = max_y + node_height/2 + 0.3
            ax.text(x_pos, label_y, label, fontsize=16, fontweight='bold',
                   color=PLAYGROUND_COLORS['text'], ha='center', va='bottom', 
                   zorder=100, clip_on=False)
    
    # Add legend for connection weights (Negative/Positive)
    legend_elements = [
        Line2D([0], [0], color='#1F77B4', lw=3, alpha=0.7, label='Negative'),
        Line2D([0], [0], color='#D62728', lw=3, alpha=0.7, label='Positive')
    ]
    # Position legend in upper right corner
    ax.legend(handles=legend_elements, loc='upper right', fontsize=16)


def animate_neuron_activations(model, X, y, recorder, resolution=50, fps=8,
                              title="What Each Neuron Responds To",
                              save_path="neuron_activations.mp4"):
    """
    Create animated video showing what each neuron responds to across the input space.
    Each neuron gets a subplot showing its activation pattern with training data overlaid.
    
    Args:
        model: Sequential model
        X: Training data (N, 2) - used to determine input space bounds
        y: Training labels (N,) - used to color data points
        recorder: TrainingRecorder with training history
        resolution: Grid resolution for activation maps
        fps: Frames per second
        title: Video title
        save_path: Path to save video
    """
    # Create mesh over input space
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution),
                        np.linspace(y_min, y_max, resolution))
    mesh_points = np.c_[xx.ravel(), yy.ravel()]
    
    # Check if model expects 3D input
    if hasattr(model.layers[0], 'W') and model.layers[0].W.shape[0] == 3:
        r = np.sqrt(mesh_points[:, 0]**2 + mesh_points[:, 1]**2).reshape(-1, 1)
        mesh_input = np.hstack([mesh_points, r])
    else:
        mesh_input = mesh_points
    
    # Extract Linear layers and their positions
    layer_info = []
    
    for i, layer in enumerate(model.layers):
        if hasattr(layer, 'W'):
            layer_info.append({
                'type': 'linear',
                'index': i,
                'in_dim': layer.W.shape[0],
                'out_dim': layer.W.shape[1]
            })
    
    # Get all layer neurons (include all layers including output)
    # Group by layer for column layout
    neurons_by_layer = {}
    for i, info in enumerate(layer_info):  # Include all layers including output
        layer_idx = info['index']
        out_dim = info['out_dim']
        if i not in neurons_by_layer:
            neurons_by_layer[i] = []
        for neuron_idx in range(out_dim):
            layer_name = f"Layer {i+1}" if i < len(layer_info) - 1 else "Output"
            neurons_by_layer[i].append({
                'layer_idx': layer_idx,
                'neuron_idx': neuron_idx,
                'layer_name': layer_name,
                'neuron_name': f"Neuron {neuron_idx}",
                'layer_group': i
            })
    
    # Flatten but maintain layer order for column layout
    hidden_neurons = []
    for layer_group in sorted(neurons_by_layer.keys()):
        hidden_neurons.extend(neurons_by_layer[layer_group])
    
    if len(hidden_neurons) == 0:
        raise ValueError("No hidden neurons found in model")
    
    # Calculate grid layout: columns = number of layers, rows = max neurons per layer
    n_layers = len(neurons_by_layer)
    max_neurons_per_layer = max([len(neurons) for neurons in neurons_by_layer.values()])
    cols = n_layers
    rows = max_neurons_per_layer
    
    # Prepare input for training data points (only compute once)
    if hasattr(model.layers[0], 'W') and model.layers[0].W.shape[0] == 3:
        X_for_activation = np.hstack([X, np.sqrt(X[:, 0]**2 + X[:, 1]**2).reshape(-1, 1)])
    else:
        X_for_activation = X
    
    # Get initial activations to determine color scale (use lower resolution for speed)
    recorder.restore_model_state(model, recorder.get_all_epochs()[0])
    initial_activations = _compute_neuron_activations(model, mesh_input, hidden_neurons)
    max_activation = max([np.abs(acts).max() for acts in initial_activations.values()])
    vmin, vmax = -max_activation, max_activation
    
    fig = plt.figure(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    gs = fig.add_gridspec(rows, cols, left=0, right=1, top=1, bottom=0, wspace=0.05, hspace=0.05)
    fig.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0.05, hspace=0.05)
    
    # Create colormap - red (negative) to white (zero) to blue (positive)
    activation_cmap = create_visualization_colormap()
    sm_activation = ScalarMappable(cmap=activation_cmap, norm=Normalize(vmin=vmin, vmax=vmax))
    sm_activation.set_array([])
    
    # Create subplot positions: arrange by columns (layers)
    axes = {}
    
    all_data_activations = _compute_all_neuron_activations_for_data(model, X_for_activation, hidden_neurons)

    # Initial plot
    for idx, neuron_info in enumerate(hidden_neurons):
        layer_group = neuron_info['layer_group']
        neuron_in_layer = neurons_by_layer[layer_group].index(neuron_info)
        ax = fig.add_subplot(gs[neuron_in_layer, layer_group])
        ax.set_facecolor('white')
        axes[idx] = ax
        
        activations = initial_activations[idx]
        Z = activations.reshape(xx.shape)
        
        # Background: activation pattern
        ax.contourf(xx, yy, Z, levels=30, cmap=activation_cmap,
                    vmin=vmin, vmax=vmax, alpha=0.6)
        ax.contour(xx, yy, Z, levels=[0], colors='black', linewidths=1.5, alpha=0.7, linestyles='--')
        
        data_activations = all_data_activations[idx]
        
        # Overlay training data points (sample if too many for performance)
        y_flat = y.flatten() if y.ndim > 1 else y
        max_points_to_plot = 500  # Limit points for performance
        if len(X) > max_points_to_plot:
            indices = np.random.choice(len(X), max_points_to_plot, replace=False)
            X_plot = X[indices]
            y_plot = y_flat[indices]
            data_activations_plot = data_activations[indices]
        else:
            X_plot = X
            y_plot = y_flat
            data_activations_plot = data_activations
        
        for i, (point, label) in enumerate(zip(X_plot, y_plot)):
            activation_val = data_activations_plot[i] if i < len(data_activations_plot) else 0
            # Size based on absolute activation (normalized)
            size = 30 + abs(activation_val) / max_activation * 100 if max_activation > 0 else 30
            # Color by label
            point_color = PLAYGROUND_COLORS['class_0'] if label == 0 else PLAYGROUND_COLORS['class_1']
            # Edge color indicates activation sign
            edge_color = 'darkblue' if activation_val > 0 else 'darkred' if activation_val < 0 else 'gray'
            ax.scatter(point[0], point[1], c=point_color, s=size, 
                      edgecolors=edge_color, linewidths=2, alpha=0.8, zorder=10)
        
        # Title with explanation
        avg_act = np.mean(np.abs(data_activations_plot)) if len(data_activations_plot) > 0 else 0
        ax.set_title(f"{neuron_info['layer_name']} - {neuron_info['neuron_name']}\n"
                    f"Avg Activation: {avg_act:.3f}", 
                    fontsize=9, fontweight='bold', color=PLAYGROUND_COLORS['text'])
        ax.set_xlim(x_min, x_max)
        ax.set_ylim(y_min, y_max)
        ax.axis('off')
    
    # Colorbar for activations (apply to all subplots)
    cbar = fig.colorbar(sm_activation, ax=list(axes.values()),
                        orientation='horizontal', pad=0.04, fraction=0.05, aspect=40)
    cbar.set_label('Activation Value', fontsize=11, fontweight='bold', color=PLAYGROUND_COLORS['text'])
    cbar.ax.tick_params(colors=PLAYGROUND_COLORS['text'], labelsize=10)
    cbar.outline.set_edgecolor('none')
    
    # Add legend explaining the visualization
    legend_text = ("Color Scheme:\n"
                  " Blue = positive activation (neuron fires)\n"
                  " White = zero activation (neutral)\n"
                  " Red = negative activation (suppressed)\n"
                  "\nPoint size = activation strength\n"
                  "Edge color = activation sign")
    fig.text(0.98, 0.9, legend_text, transform=fig.transFigure,
            fontsize=10, color=PLAYGROUND_COLORS['text'],
            verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, 
                     edgecolor=PLAYGROUND_COLORS['grid']))
    
    # Add layer labels at the top of each column
    for layer_group in sorted(neurons_by_layer.keys()):
        col = layer_group
        # Add text at top of column
        fig.text((col + 0.5) / cols, 0.91, f"Layer {layer_group + 1}",
                transform=fig.transFigure, fontsize=12, fontweight='bold',
                color=PLAYGROUND_COLORS['text'], ha='center',
                bbox=dict(boxstyle='round', facecolor=PLAYGROUND_COLORS['accent'],
                         alpha=0.8, edgecolor=PLAYGROUND_COLORS['grid']))
    
    # Add epoch text
    epoch_text = fig.text(0.05, 0.93, '', transform=fig.transFigure,
                         fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'],
                         verticalalignment='top', bbox=dict(boxstyle='round',
                         facecolor='white', alpha=0.9, edgecolor=PLAYGROUND_COLORS['grid']))
    
    
    # Animation function
    def animate(frame):
        epoch = recorder.get_all_epochs()[frame]
        state = recorder.get_state_at_epoch(epoch)
        
        # Restore model state
        recorder.restore_model_state(model, epoch)
        
        # Compute activations
        activations = _compute_neuron_activations(model, mesh_input, hidden_neurons)
        all_data_activations = _compute_all_neuron_activations_for_data(model, X_for_activation, hidden_neurons)
        
        # Update plots
        y_flat = y.flatten() if y.ndim > 1 else y
        max_points_to_plot = 500  # Limit points for performance
        
        for idx, neuron_info in enumerate(hidden_neurons):
            ax = axes[idx]
            ax.clear()
            ax.set_facecolor('white')
            
            Z = activations[idx].reshape(xx.shape)
            
            # Background: activation pattern
            ax.contourf(xx, yy, Z, levels=30, cmap=activation_cmap,
                        vmin=vmin, vmax=vmax, alpha=0.6)
            ax.contour(xx, yy, Z, levels=[0], colors='black', linewidths=1.5,
                       alpha=0.7, linestyles='--')
            
            data_activations = all_data_activations[idx]
            
            # Overlay training data points (sample if too many for performance)
            if len(X) > max_points_to_plot:
                indices = np.random.choice(len(X), max_points_to_plot, replace=False)
                X_plot = X[indices]
                y_plot = y_flat[indices]
                data_activations_plot = data_activations[indices]
            else:
                X_plot = X
                y_plot = y_flat
                data_activations_plot = data_activations
            
            for i, (point, label) in enumerate(zip(X_plot, y_plot)):
                activation_val = data_activations_plot[i] if i < len(data_activations_plot) else 0
                # Size based on absolute activation
                size = 30 + abs(activation_val) / max_activation * 100 if max_activation > 0 else 30
                # Color by label
                point_color = PLAYGROUND_COLORS['class_0'] if label == 0 else PLAYGROUND_COLORS['class_1']
                # Edge color indicates activation sign
                edge_color = 'darkblue' if activation_val > 0 else 'darkred' if activation_val < 0 else 'gray'
                ax.scatter(point[0], point[1], c=point_color, s=size,
                           edgecolors=edge_color, linewidths=2, alpha=0.8, zorder=10)
            
            # Title with average activation
            avg_act = np.mean(np.abs(data_activations_plot)) if len(data_activations_plot) > 0 else 0
            ax.set_title(f"{neuron_info['layer_name']} - {neuron_info['neuron_name']}\n"
                         f"Avg Activation: {avg_act:.3f}",
                         fontsize=9, fontweight='bold', color=PLAYGROUND_COLORS['text'])
            ax.set_xlim(x_min, x_max)
            ax.set_ylim(y_min, y_max)
            ax.axis('off')
        
        # Update text
        loss_val = state.get('loss', 0)
        acc_val = state.get('accuracy', 0)
        epoch_text.set_text(f'Epoch: {epoch} | Loss: {loss_val:.4f} | Accuracy: {acc_val:.2%}')
        
        return list(axes.values()) + [epoch_text]
    
    # Create animation
    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                        blit=False, repeat=True)
    
    # Save video
    print(f"Creating neuron activations video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")
    
    return anim, fig


def _compute_neuron_activations(model, mesh_input, hidden_neurons):
    """
    Compute activation values for each hidden neuron across the input space.
    Returns a dict mapping neuron index to activation array.
    """
    activations = {}
    
    # Forward pass through model, collecting activations after each activation function
    x = mesh_input
    layer_outputs = {}  # Store outputs after each layer (indexed by model layer index)
    
    for i, layer in enumerate(model.layers):
        x = layer.forward(x)
        # Store output after this layer (this will be after activation if it's an activation layer)
        layer_outputs[i] = x.copy()
    
    # Extract activations for each hidden neuron
    # hidden_neurons has 'layer_idx' which is the model layer index where the neuron lives
    for idx, neuron_info in enumerate(hidden_neurons):
        layer_idx = neuron_info['layer_idx']
        neuron_idx = neuron_info['neuron_idx']
        
        # The layer_idx points to the Linear layer, but we want activations AFTER the activation function
        # So we need to find the activation layer that comes after this Linear layer
        target_layer_idx = None
        
        # Find the activation layer that follows this Linear layer
        for i in range(layer_idx + 1, len(model.layers)):
            if not hasattr(model.layers[i], 'W'):
                # This is an activation function
                target_layer_idx = i
                break
        
        # If no activation found, use the linear layer output directly
        if target_layer_idx is None:
            target_layer_idx = layer_idx
        
        if target_layer_idx in layer_outputs:
            layer_acts = layer_outputs[target_layer_idx]
            if layer_acts.shape[1] > neuron_idx:
                activations[idx] = layer_acts[:, neuron_idx]
            else:
                activations[idx] = np.zeros(len(mesh_input))
        else:
            activations[idx] = np.zeros(len(mesh_input))
    
    return activations


def _compute_all_neuron_activations_for_data(model, X, hidden_neurons):
    """
    Compute activation values for all neurons for given data points in one forward pass.
    Returns dict mapping neuron index to activation array.
    Much more efficient than computing individually.
    """
    # Single forward pass through model
    x = X
    layer_outputs = {}
    
    for i, layer in enumerate(model.layers):
        x = layer.forward(x)
        layer_outputs[i] = x.copy()
    
    # Extract activations for all neurons
    activations = {}
    for idx, neuron_info in enumerate(hidden_neurons):
        layer_idx = neuron_info['layer_idx']
        neuron_idx = neuron_info['neuron_idx']
        
        # Find the activation layer that follows this neuron's Linear layer
        target_layer_idx = None
        for i in range(layer_idx + 1, len(model.layers)):
            if not hasattr(model.layers[i], 'W'):
                target_layer_idx = i
                break
        
        if target_layer_idx is None:
            target_layer_idx = layer_idx
        
        if target_layer_idx in layer_outputs:
            layer_acts = layer_outputs[target_layer_idx]
            if layer_acts.shape[1] > neuron_idx:
                activations[idx] = layer_acts[:, neuron_idx]
            else:
                activations[idx] = np.zeros(len(X))
        else:
            activations[idx] = np.zeros(len(X))
    
    return activations


def animate_loss_landscape_2d(model, X, y, loss_fn, recorder, resolution=50, fps=10,
                              title="2D Loss Landscape with Training Trajectory",
                              save_path="loss_landscape_2d.mp4"):
    """
    Create animated video showing 2D loss landscape with training trajectory.
    Shows how the model moves through parameter space toward the minimum.
    
    Args:
        model: Sequential model
        X: Training data (N, features)
        y: Training labels (N,)
        loss_fn: Loss function
        recorder: TrainingRecorder with training history
        resolution: Grid resolution for loss landscape
        fps: Frames per second
        title: Video title
        save_path: Path to save video
    """
    # Use the standard "two basis directions" approach for loss landscapes
    # This is the approach used in the loss landscape visualization paper
    # Direction 1: from initial to final parameters (main training direction)
    # Direction 2: random direction orthogonal to direction 1
    
    # Get initial and final parameters
    initial_epoch = recorder.get_all_epochs()[0]
    final_epoch = recorder.get_all_epochs()[-1]
    
    recorder.restore_model_state(model, initial_epoch)
    initial_params = _get_model_parameters(model)
    
    recorder.restore_model_state(model, final_epoch)
    final_params = _get_model_parameters(model)
    
    # Use initial parameters as center
    center_params = initial_params.copy()
    
    # Direction 1: from initial to final (the main training direction)
    direction1 = final_params - initial_params
    direction1_norm = np.linalg.norm(direction1)
    if direction1_norm > 1e-10:
        direction1 = direction1 / direction1_norm
    else:
        # If no change, use a random direction
        direction1 = np.random.randn(len(initial_params))
        direction1 = direction1 / np.linalg.norm(direction1)
    
    # Direction 2: random direction orthogonal to direction 1
    # Generate random vector and make it orthogonal
    direction2 = np.random.randn(len(initial_params))
    # Remove component parallel to direction1 (Gram-Schmidt)
    direction2 = direction2 - np.dot(direction2, direction1) * direction1
    direction2_norm = np.linalg.norm(direction2)
    if direction2_norm > 1e-10:
        direction2 = direction2 / direction2_norm
    else:
        # If orthogonalization failed, generate a new random direction
        direction2 = np.random.randn(len(initial_params))
        direction2 = direction2 - np.dot(direction2, direction1) * direction1
        direction2 = direction2 / np.linalg.norm(direction2)
    
    print(f"Using two basis directions:")
    print(f"  Direction 1: Initial  Final (training direction)")
    print(f"  Direction 2: Random orthogonal direction")
    
    # Project trajectory onto 2D space and verify loss values
    trajectory = []
    trajectory_losses = []
    trajectory_alphas = []
    trajectory_betas = []
    trajectory_losses_verified = []  # Loss computed at actual parameter points
    
    for epoch in recorder.get_all_epochs():
        recorder.restore_model_state(model, epoch)
        params = _get_model_parameters(model)
        
        # Project onto 2D space using basis directions
        alpha = np.dot(params - center_params, direction1)
        beta = np.dot(params - center_params, direction2)
        trajectory.append((alpha, beta))
        trajectory_alphas.append(alpha)
        trajectory_betas.append(beta)
        
        # Get loss at this epoch (from recorder)
        state = recorder.get_state_at_epoch(epoch)
        trajectory_losses.append(state.get('loss', 0))
        
        # Verify loss by computing it at the actual parameters
        y_pred = model.forward(X)
        verified_loss = loss_fn.calculate(y_pred, y)
        trajectory_losses_verified.append(verified_loss)
    
    # Adjust grid bounds to include the full trajectory with padding
    alpha_min, alpha_max = min(trajectory_alphas), max(trajectory_alphas)
    beta_min, beta_max = min(trajectory_betas), max(trajectory_betas)
    
    # Add padding (20% on each side)
    alpha_padding = (alpha_max - alpha_min) * 0.2 if alpha_max > alpha_min else 0.5
    beta_padding = (beta_max - beta_min) * 0.2 if beta_max > beta_min else 0.5
    
    alpha_range = np.linspace(alpha_min - alpha_padding, alpha_max + alpha_padding, resolution)
    beta_range = np.linspace(beta_min - beta_padding, beta_max + beta_padding, resolution)
    alpha_grid, beta_grid = np.meshgrid(alpha_range, beta_range)
    
    # Create loss landscape by interpolating from actual trajectory losses
    # This ensures the landscape matches the actual training losses at trajectory points
    print("Creating loss landscape from actual training losses (interpolating)...")
    
    # Extract trajectory coordinates and their actual losses
    traj_alphas_array = np.array(trajectory_alphas)
    traj_betas_array = np.array(trajectory_betas)
    traj_losses_array = np.array(trajectory_losses_verified)
    
    # Create grid
    alpha_grid, beta_grid = np.meshgrid(alpha_range, beta_range)
    
    # Interpolate loss values from trajectory points to grid
    loss_landscape = None
    if RBFInterpolator is not None:
        try:
            # RBF interpolation - smooth and matches data points exactly
            print("  Using RBF interpolation for smooth landscape...")
            rbf = RBFInterpolator(
                np.column_stack((traj_alphas_array, traj_betas_array)),
                traj_losses_array,
                kernel='thin_plate_spline',  # Smooth interpolation
                smoothing=0.0  # Exact match at data points
            )
            
            # Evaluate on grid
            grid_points = np.column_stack((alpha_grid.ravel(), beta_grid.ravel()))
            loss_landscape = rbf(grid_points).reshape(alpha_grid.shape)
        except Exception as e:
            print(f"  RBF interpolation failed ({e}), will attempt griddata fallback...")
    
    if loss_landscape is None:
        if griddata is None:
            raise ImportError(
                "scipy.interpolate.griddata is required to compute the loss landscape. "
                "Install SciPy or provide precomputed landscape data."
            )
        
        print("  Using griddata interpolation for loss landscape...")
        points = np.column_stack((traj_alphas_array, traj_betas_array))
        values = traj_losses_array
        
        # Try cubic first (smooth)
        loss_landscape = griddata(points, values, (alpha_grid, beta_grid),
                                  method='cubic', fill_value=np.nan)
        
        # Fill NaN with linear interpolation
        if np.any(np.isnan(loss_landscape)):
            loss_landscape_linear = griddata(points, values, (alpha_grid, beta_grid),
                                             method='linear', fill_value=np.nan)
            loss_landscape = np.where(~np.isnan(loss_landscape), loss_landscape,
                                      loss_landscape_linear)
        
        # Fill remaining NaN with nearest neighbor
        if np.any(np.isnan(loss_landscape)):
            loss_landscape_nn = griddata(points, values, (alpha_grid, beta_grid),
                                         method='nearest')
            loss_landscape = np.where(~np.isnan(loss_landscape), loss_landscape,
                                      loss_landscape_nn)
    
    # Clamp loss values to realistic bounds (interpolation can create invalid values)
    # Loss functions like cross-entropy should always be >= 0, but we clamp to
    # the actual observed range to avoid showing unrealistic values
    min_observed_loss = np.min(traj_losses_array)
    max_observed_loss = np.max(traj_losses_array)
    
    # Clamp to observed range (with small padding for visualization)
    # This ensures we don't show loss=0 (which would mean perfect predictions, unlikely)
    # or negative values (which are impossible)
    loss_range = max_observed_loss - min_observed_loss
    min_clamp = max(0.0, min_observed_loss - loss_range * 0.1)  # Allow small extrapolation below min
    max_clamp = max_observed_loss + loss_range * 0.5  # Allow some extrapolation above max
    
    loss_landscape = np.clip(loss_landscape, min_clamp, max_clamp)
    
    # Verify: check that landscape matches trajectory losses at trajectory points
    print("  Verifying landscape matches trajectory losses...")
    for i, (alpha, beta, true_loss) in enumerate(zip(traj_alphas_array, traj_betas_array, traj_losses_array)):
        # Find closest grid point
        alpha_idx = np.argmin(np.abs(alpha_range - alpha))
        beta_idx = np.argmin(np.abs(beta_range - beta))
        landscape_loss = loss_landscape[beta_idx, alpha_idx]
        diff = abs(landscape_loss - true_loss)
        if diff > 0.01:  # Warn if difference is significant
            if i == 0 or i == len(traj_alphas_array) - 1:  # Only warn for first/last
                print(f"    Warning: Point {i} loss mismatch: {true_loss:.6f} vs {landscape_loss:.6f} (diff: {diff:.6f})")
    
    print("Loss landscape created from actual training losses!")
    
    # Find min/max for visualization
    # Include trajectory losses to ensure they're visible
    loss_min = min(np.min(loss_landscape), min(trajectory_losses_verified))
    loss_max = max(np.max(loss_landscape), max(trajectory_losses_verified))
    
    # Add small padding to range
    loss_range = loss_max - loss_min
    loss_min -= loss_range * 0.05
    loss_max += loss_range * 0.05
    
    # Setup figure (16:9) - full bleed, matching decision boundary styling
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor(PLAYGROUND_COLORS['background'])
    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)
    
    # Create colormap for loss (low = blue, high = red)
    loss_colors = ['#3E6589', '#95E1D3', '#FFD93D', '#D87373']
    loss_cmap = LinearSegmentedColormap.from_list('loss', loss_colors, N=256)
    
    # Initial plot: loss landscape
    contour = ax.contourf(alpha_grid, beta_grid, loss_landscape, levels=50,
                          cmap=loss_cmap, vmin=loss_min, vmax=loss_max, alpha=0.8)
    ax.contour(alpha_grid, beta_grid, loss_landscape, levels=20,
              colors='black', linewidths=0.5, alpha=0.3)
    
    # Colorbar (vertical, inset on the right inside the plot)
    pos = ax.get_position()
    cbar_width = 0.01 * pos.width
    cbar_height = 0.6 * pos.height
    cbar_left = pos.x1 - cbar_width * 7
    cbar_bottom = pos.y0 + (pos.height - cbar_height) / 2
    cbar_ax = fig.add_axes([cbar_left, cbar_bottom, cbar_width, cbar_height])
    loss_norm = Normalize(vmin=loss_min, vmax=loss_max)
    sm_loss = ScalarMappable(norm=loss_norm, cmap=loss_cmap)
    sm_loss.set_array([])
    tick_vals = np.linspace(loss_min, loss_max, 4)
    cbar = fig.colorbar(sm_loss, cax=cbar_ax, orientation='vertical', ticks=tick_vals)
    cbar.ax.tick_params(colors=PLAYGROUND_COLORS['text'], labelsize=16, length=0)
    cbar.outline.set_edgecolor('none')
    cbar.ax.set_ylabel('Loss', fontsize=16, fontweight='bold', color=PLAYGROUND_COLORS['text'], labelpad=10)
    
    def _style_axes(axis: plt.Axes):
        axis.set_facecolor('white')
        axis.set_xlim(alpha_range[0], alpha_range[-1])
        axis.set_ylim(beta_range[0], beta_range[-1])

        # Set major ticks to be inside the plot for both axes
        axis.tick_params(axis='x', which='major', direction='in', labeltop=False, labelbottom=True, pad=-25, labelsize=16)
        axis.tick_params(axis='y', which='major', direction='in', labelright=False, labelleft=True, pad=-45, labelsize=16)
        for spine in axis.spines.values():
            spine.set_visible(False)
        axis.grid(True, color=PLAYGROUND_COLORS['grid'], alpha=0.25, linestyle='--', linewidth=0.6)
    _style_axes(ax)
    
    info_text = fig.text(
        0.06,
        0.93,
        '',
        fontsize=16,
        fontweight='bold',
        color=PLAYGROUND_COLORS['text'],
        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9,
                  edgecolor=PLAYGROUND_COLORS['grid'])
    )
    
    # Animation function
    def animate(frame):
        ax.clear()
        ax.set_facecolor('white')
        
        # Redraw loss landscape
        contour = ax.contourf(alpha_grid, beta_grid, loss_landscape, levels=50,
                             cmap=loss_cmap, vmin=loss_min, vmax=loss_max, alpha=0.8)
        ax.contour(alpha_grid, beta_grid, loss_landscape, levels=20,
                  colors='black', linewidths=0.5, alpha=0.3)
        _style_axes(ax)
        cbar.update_normal(contour)
        
        # Draw trajectory up to current frame
        current_trajectory = trajectory[:frame+1]
        current_losses = trajectory_losses_verified[:frame+1]  # Use actual losses from training
        
        if len(current_trajectory) > 1:
            traj_alpha = [t[0] for t in current_trajectory]
            traj_beta = [t[1] for t in current_trajectory]
            
            # Draw trajectory line - the landscape now matches actual losses via interpolation
            # So we can just draw a clean line that follows the landscape colors
            ax.plot(traj_alpha, traj_beta, 'o-', color='white', linewidth=3,
                   markersize=6, alpha=0.9, label='Training Path', zorder=10)
            
            # Draw current position with color based on actual current loss
            if len(current_losses) > 0:
                current_loss = current_losses[-1]
                # Normalize current loss relative to landscape
                if loss_max > loss_min:
                    loss_norm = (current_loss - loss_min) / (loss_max - loss_min)
                    loss_norm = max(0, min(1, loss_norm))  # Clamp to [0, 1]
                else:
                    loss_norm = 0.5
                marker_color = loss_cmap(1 - loss_norm)  # Invert so blue = low loss
            else:
                marker_color = 'yellow'
            
            # Highlight current position with star
            ax.scatter(traj_alpha[-1], traj_beta[-1], s=300, c=marker_color,
                      edgecolors='black', linewidths=3, marker='*', zorder=12,
                      label='Current Position')
        
        # Update text with actual loss from training
        epoch = recorder.get_all_epochs()[frame]
        loss_val = current_losses[-1] if current_losses else 0
        info_text.set_text(f"Epoch {epoch}\nLoss: {loss_val:.6f}")
        
        return contour, info_text
    
    # Create animation
    n_frames = len(recorder.history)
    anim = FuncAnimation(fig, animate, frames=n_frames, interval=1000/fps,
                        blit=False, repeat=True)
    
    # Save video
    print(f"Creating loss landscape video with {n_frames} frames...")
    try:
        writer = FFMpegWriter(fps=fps, bitrate=1800)
        anim.save(save_path, writer=writer)
        print(f"Video saved to {save_path}")
    except Exception as e:
        print(f"FFmpeg not available, trying Pillow (GIF)...")
        try:
            gif_path = save_path.replace('.mp4', '.gif')
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer)
            print(f"GIF saved to {gif_path}")
        except Exception as e2:
            print(f"Error saving video: {e2}")
            print("Make sure FFmpeg is installed: brew install ffmpeg")
    
    return anim, fig


def _get_model_parameters(model):
    """Extract all parameters from model and flatten into 1D array."""
    params = []
    for layer in model.layers:
        if hasattr(layer, 'W'):
            params.append(layer.W.flatten())
        if hasattr(layer, 'b'):
            params.append(layer.b.flatten())
    return np.concatenate(params) if params else np.array([])

